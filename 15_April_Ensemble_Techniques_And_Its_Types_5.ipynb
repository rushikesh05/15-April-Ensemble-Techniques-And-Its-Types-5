{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Q1. Assignment"
      ],
      "metadata": {
        "id": "l_sW5C_lcHCY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tips.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJ8zfLze0WqI",
        "outputId": "71745618-1c5d-4762-f808-09e4584d217f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['total_bill', 'tip', 'sex', 'smoker', 'day', 'time', 'size'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Load the tips dataset\n",
        "tips = sns.load_dataset('tips')\n",
        "X = tips.drop('sex', axis=1)\n",
        "y = tips['sex']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create numerical and categorical pipelines\n",
        "num_pipeline = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "cat_pipeline = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('encoder', OneHotEncoder())\n",
        "])\n",
        "\n",
        "# Identify the categorical and numerical columns\n",
        "num_cols = X.select_dtypes(include=['float64', 'int64']).columns\n",
        "cat_cols = X.select_dtypes(include=['category', 'object']).columns\n",
        "\n",
        "# Combine numerical and categorical pipelines using ColumnTransformer\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('num', num_pipeline, num_cols),\n",
        "    ('cat', cat_pipeline, cat_cols)\n",
        "])\n",
        "\n",
        "# Create the final pipeline with preprocessor and Random Forest Classifier\n",
        "pipe = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('clf', RandomForestClassifier(random_state=42))\n",
        "])\n",
        "\n",
        "# Fit the pipeline on the training data\n",
        "pipe.fit(X_train, y_train)\n",
        "\n",
        "# Predict the target variable on the testing data\n",
        "y_pred = pipe.predict(X_test)\n",
        "\n",
        "# Evaluate the model using accuracy and classification report\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print('Accuracy: {:.2f}'.format(acc))\n",
        "\n",
        "report = classification_report(y_test, y_pred)\n",
        "print('Classification Report:\\n', report)\n"
      ],
      "metadata": {
        "id": "KHETrwDWdkAg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d4133c5-c57e-4142-a888-1f1b6a6c0d91"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.61\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      Female       0.50      0.37      0.42        19\n",
            "        Male       0.66      0.77      0.71        30\n",
            "\n",
            "    accuracy                           0.61        49\n",
            "   macro avg       0.58      0.57      0.57        49\n",
            "weighted avg       0.60      0.61      0.60        49\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###In this  pipeline, we use the tips dataset and split it into training and testing sets. We create separate pipelines for numerical and categorical features, and combine them using ColumnTransformer. We then use Random Forest Classifier instead of Logistic Regression to build the final model. Finally, we fit the pipeline on the training data, predict the target variable on the testing data, and evaluate the model using accuracy and classification report."
      ],
      "metadata": {
        "id": "h0_pXbTC6Qvt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Here's an  pipeline using the titanic dataset from Seaborn, where we predict the survival of passengers based on their features:"
      ],
      "metadata": {
        "id": "6BHVIwZY5jeC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Load the titanic dataset\n",
        "titanic = sns.load_dataset('titanic')\n",
        "X = titanic.drop('survived', axis=1)\n",
        "y = titanic['survived']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create numerical and categorical pipelines\n",
        "num_pipeline = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "cat_pipeline = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('encoder', OneHotEncoder())\n",
        "])\n",
        "\n",
        "# Identify the categorical and numerical columns\n",
        "num_cols = X.select_dtypes(include=['float64', 'int64']).columns\n",
        "cat_cols = X.select_dtypes(include=['category', 'object']).columns\n",
        "\n",
        "# Combine numerical and categorical pipelines using ColumnTransformer\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('num', num_pipeline, num_cols),\n",
        "    ('cat', cat_pipeline, cat_cols)\n",
        "])\n",
        "\n",
        "# Create the final pipeline with preprocessor and Random Forest Classifier\n",
        "pipe = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('clf', RandomForestClassifier(random_state=42))\n",
        "])\n",
        "\n",
        "# Fit the pipeline on the training data\n",
        "pipe.fit(X_train, y_train)\n",
        "\n",
        "# Predict the target variable on the testing data\n",
        "y_pred = pipe.predict(X_test)\n",
        "\n",
        "# Evaluate the model using accuracy and classification report\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print('Accuracy: {:.2f}'.format(acc))\n",
        "\n",
        "report = classification_report(y_test, y_pred)\n",
        "print('Classification Report:\\n', report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Qs37hCtz4MC",
        "outputId": "c35b5d8a-61ed-403e-86bb-f2699fe9ae77"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.00\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       105\n",
            "           1       1.00      1.00      1.00        74\n",
            "\n",
            "    accuracy                           1.00       179\n",
            "   macro avg       1.00      1.00      1.00       179\n",
            "weighted avg       1.00      1.00      1.00       179\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q2. Build a pipeline that includes a random forest classifier and a logistic regression classifier, and then use a voting classifier to combine their predictions. Train the pipeline on the iris dataset and evaluate its accuracy."
      ],
      "metadata": {
        "id": "9EcCiOht66-y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "iris = load_iris()\n",
        "\n",
        "# create numerical and categorical transformers\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('scaler', StandardScaler())])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('onehot', OneHotEncoder())])\n",
        "\n",
        "# specify the columns that should be transformed\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, [0, 1, 2, 3]),\n",
        "        ('cat', categorical_transformer, [])])\n",
        "\n",
        "# create the random forest and logistic regression classifiers\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "lr = LogisticRegression(random_state=42)\n",
        "\n",
        "# create a voting classifier with the random forest and logistic regression classifiers\n",
        "voting_clf = VotingClassifier(estimators=[('rf', rf), ('lr', lr)], voting='hard')\n",
        "\n",
        "# create the final pipeline by combining the preprocessor and the voting classifier\n",
        "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                           ('voting_clf', voting_clf)])\n",
        "\n",
        "# split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2, random_state=42)\n",
        "\n",
        "# train the pipeline\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# evaluate the accuracy of the pipeline on the test set\n",
        "accuracy = pipeline.score(X_test, y_test)\n",
        "print(f\"Accuracy: {accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9j2y_99h5b2l",
        "outputId": "9707cfae-bf5e-468d-9b84-ea871e5d5a69"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8r5SAyN164J0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}